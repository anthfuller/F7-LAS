# F7-LAS Documentation

![F7-LAS CI](https://github.com/anthfuller/F7-LAS/actions/workflows/f7las-ci.yml/badge.svg?branch=main)

A multi-layer agentic security framework for governing, evaluating, and enforcing controls across AI agents, models, and orchestration pipelines.

# F7-LAS â€” Fuller 7-Layer Agentic AI Security Framework

![Version](https://img.shields.io/badge/version-v3.1-blue)
![License](https://img.shields.io/badge/license-Proprietary-lightgrey)
![CI](https://img.shields.io/github/actions/workflow/status/anthfuller/F7-LAS/f7las-ci.yml)

---

### TL;DR

**F7-LAS** (Fuller 7-Layer Agentic AI Security Framework) is a vendor-neutral, control-centric model for securing advanced agentic and multi-agent AI systems. It supports SOC, AI security architects, and governance teams working across real-world deployments.

ðŸ“„ [Download the White Paper (v2.4)](docs/Security_Agentic_AI_The_7-Layer_Model_v2.4.pdf)

---

## ðŸŒ Overview

F7-LAS defines a layered control model for securing AI agents that can plan, reason, call tools, modify systems, and interact with enterprise environments.

It provides:
- A 7-layer control stack (L1â€“L7)
- A supplemental supply-chain layer (Layer S)
- A full implementation guide, patterns, controls, and engineering checklists
- A vendor-neutral reference architecture for multi-agent systems
- A DevSecOps pipeline enforcing prompt, tool, policy, and scenario integrity

**Status**: v3.1 â€” Conceptual model stable, with expanding implementation patterns, controls, and CI pipeline integration.

---

## What F7-LAS Covers

F7-LAS models agentic system security across seven layers:

1. **System Prompt (Soft Policy)**
2. **RAG / Grounding (Epistemic Guardrail)**
3. **Agent Planner / Controller**
4. **Tools & Integrations (Action Surface)**
5. **Policy Engine Outside the LLM (PDP/PEP Hard Guardrails)**
6. **Sandboxed Execution Environment (Blast Radius Control)**
7. **Monitoring, Evaluation & Assurance**

Additional components:
- **Layer S â€” Supply Chain Security (SBOM, SCA, attestation)**
- **Model Security Annex**
- Risk scoring, metrics, and SLOs
- Operational playbooks
- RACI model
- Implementation profiles

F7-LAS complements (but does not directly map to):
NIST AI RMF, ISO/IEC 42001, EU AI Act, MITRE ATT&CK, MITRE ATLAS

---

## ðŸ—‚ Repository Structure

```bash
F7-LAS/
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ f7las-ci.yml
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ validate-prompts.py
â”‚   â”œâ”€â”€ validate_policies.py
â”‚   â”œâ”€â”€ validate_settings.py
â”‚   â””â”€â”€ check_golden_thresholds.py
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â”œâ”€â”€ coordinator-agent-prompt-v1.txt
â”‚   â”‚   â”œâ”€â”€ investigator-agent-prompt-v1.txt
â”‚   â”‚   â””â”€â”€ remediator-agent-prompt-v1.txt
â”‚   â”‚
â”‚   â”œâ”€â”€ policies/
â”‚   â”‚   â”œâ”€â”€ model-policy-baseline.yaml
â”‚   â”‚   â”œâ”€â”€ agent-policy-baseline.yaml
â”‚   â”‚   â””â”€â”€ data-policy-baseline.yaml
â”‚   â”‚
â”‚   â”œâ”€â”€ settings.yaml
â”‚   â”œâ”€â”€ psp-schema.json
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ F7-LAS-Control-Catalog-v0.1.md
â”‚   â”œâ”€â”€ Engineering-Review-Checklist.md
â”‚   â”œâ”€â”€ Multi-Agent-F7-LAS-Architecture.png
â”‚   â”‚
â”‚   â”œâ”€â”€ f7-las-implementation-guide/
â”‚   â”‚   â”œâ”€â”€ 00-introduction.md
â”‚   â”‚   â”œâ”€â”€ 01-control-objectives.md
â”‚   â”‚   â”œâ”€â”€ 02-layer-by-layer-controls.md
â”‚   â”‚   â”œâ”€â”€ 03-supplemental-layer-s.md
â”‚   â”‚   â”œâ”€â”€ 04-model-security-annex.md
â”‚   â”‚   â”œâ”€â”€ 05-metrics-and-slos.md
â”‚   â”‚   â”œâ”€â”€ 06-operational-playbooks.md
â”‚   â”‚   â”œâ”€â”€ 07-raci-model.md
â”‚   â”‚   â”œâ”€â”€ 08-implementation-profiles.md
â”‚   â”‚   â””â”€â”€ appendices/
â”‚   â”‚       â”œâ”€â”€ a-schemas.md
â”‚   â”‚       â”œâ”€â”€ b-templates.md
â”‚   â”‚       â”œâ”€â”€ c-checklist.md
â”‚   â”‚       â””â”€â”€ d-reference-architectures.md
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ tools/
â”‚   â””â”€â”€ demo_runner/
â”‚       â””â”€â”€ run_golden_dataset.py
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ golden_dataset/
â”‚   â”‚   â”œâ”€â”€ rubric.json
â”‚   â”‚   â””â”€â”€ scenarios.json
â”‚   â”‚
â”‚   â””â”€â”€ test_agents_basic.py
â”‚
â””â”€â”€ examples/

```
---

## Quick Start

```bash
git clone https://github.com/anthfuller/F7-LAS.git
cd F7-LAS
python scripts/validate-prompts.py
```

See `demo-runner/` for sample agent orchestration.

---

## Usage Scenarios

- Embed F7-LAS into SOC workflows
- Secure AI-driven remediation agents
- Evaluate tool-call safety & sandboxing in production
- Align agent design to NIST AI RMF, ISO/IEC 42001, and EU AI Act

---

## How to Cite

If referencing this work in research or policy:

> Fuller, A. (2025). *Security for Agentic AI: The F7-LAS Framework for Multi-Layer Controls.* [https://github.com/anthfuller/F7-LAS](https://github.com/anthfuller/F7-LAS)

---

## Contributing

Contributions welcomed â€” scenarios, policies, controls, tooling, and improvements.

Please open an issue before major changes.

---

## License & Disclaimer

Â© 2025 Anthony L. Fuller. All rights reserved.

#### This work is created independently by the author and is not affiliated with, endorsed by, or associated with Microsoft or any other employer. Opinions and materials represent the authorâ€™s personal work.
